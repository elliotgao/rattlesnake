# rattlesnake

This is an near finished project, attempting to minize the complexity (deepness especially) of 
artificial neural network but still, maintaining the performances of deep networks.

The purpose of this technique is to make the training more efficient (shorter time) and potentially 
faster deployment (small network architecture) in small devices.

Detailed report will be uploaded by the end of December 2017.
